{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0002a1d56b766486e161a3f06a8fa14f2818ee149eeb73a14d72be53c07d13fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout, Flatten, Dense, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6.0)\n",
    "\n",
    "\n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    return Activation(relu6)(x)\n",
    "\n",
    "\n",
    "def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    # Width\n",
    "    cchannel = int(filters * alpha)\n",
    "\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    if r:\n",
    "        x = Add()([x, inputs])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\n",
    "    x = _bottleneck(inputs, filters, kernel, t, alpha, strides)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNetv2(input_shape, k, alpha=1.0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    first_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = _conv_block(inputs, first_filters, (3, 3), strides=(2, 2))\n",
    "\n",
    "    x = _inverted_residual_block(x, 16, (3, 3), t=1, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 24, (3, 3), t=6, alpha=alpha, strides=2, n=2)\n",
    "    x = _inverted_residual_block(x, 32, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 64, (3, 3), t=6, alpha=alpha, strides=2, n=4)\n",
    "    x = _inverted_residual_block(x, 96, (3, 3), t=6, alpha=alpha, strides=1, n=3)\n",
    "    x = _inverted_residual_block(x, 160, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 320, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    if alpha > 1.0:\n",
    "        last_filters = _make_divisible(1280 * alpha, 8)\n",
    "    else:\n",
    "        last_filters = 1280\n",
    "\n",
    "    x = _conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    x = Dense(128, activation = 'relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(k, activation = 'softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = MobileNetv2((224, 224, 3), 100, 1.0)\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    " \n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    " \n",
    "# define cnn model\n",
    "def define_model(trainX):\n",
    "    model = MobileNetv2(input_shape=trainX.shape[1:],k = 10, alpha=1.0)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model(trainX)\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}